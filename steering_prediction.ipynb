{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# defining customized Dataset class for Udacity\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class UdacityDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, select_camera=None, select_range=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            select_camera (string): 'left_ / right_ / center_camera'\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        camera_csv = pd.read_csv(csv_file)\n",
    "        assert select_camera in ['left_camera', 'right_camera', 'center_camera'], \"Invalid camera: {}\".format(select_camera)\n",
    "        if select_camera:\n",
    "            camera_csv = camera_csv[camera_csv['frame_id']==select_camera]\n",
    "        if select_range:\n",
    "            camera_csv = camera_csv.iloc[select_range[0]: select_range[1]]\n",
    "        self.camera_csv = camera_csv\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.camera_csv)\n",
    "    \n",
    "    def read_data_single(self, idx):\n",
    "        path = os.path.join(self.root_dir, self.camera_csv['filename'].iloc[idx])\n",
    "        image = io.imread(path)\n",
    "        timestamp = self.camera_csv['timestamp'].iloc[idx]\n",
    "        frame_id = self.camera_csv['frame_id'].iloc[idx]\n",
    "        angle = self.camera_csv['angle'].iloc[idx]\n",
    "        torque = self.camera_csv['torque'].iloc[idx]\n",
    "        speed = self.camera_csv['speed'].iloc[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image_transformed = self.transform(image)\n",
    "            del image\n",
    "            image = image_transformed\n",
    "        angle_t = torch.tensor(angle)\n",
    "        torque_t = torch.tensor(torque)\n",
    "        speed_t = torch.tensor(speed)\n",
    "        del angle, torque, speed\n",
    "            \n",
    "        return image, timestamp, frame_id, angle_t, torque_t, speed_t\n",
    "    \n",
    "    def read_data(self, idx):\n",
    "        if isinstance(idx, list):\n",
    "            data = None\n",
    "            for i in idx:\n",
    "                new_data = self.read_data(i)\n",
    "                if data is None:\n",
    "                    data = [[] for _ in range(len(new_data))]\n",
    "                for i, d in enumerate(new_data):\n",
    "                    data[i].append(new_data[i])\n",
    "                del new_data\n",
    "                \n",
    "            for stack_idx in [0, 3, 4, 5]: # we don't stack timestamp and frame_id since those are string data\n",
    "                data[stack_idx] = torch.stack(data[stack_idx])\n",
    "            \n",
    "            return data\n",
    "        \n",
    "        else:\n",
    "            return self.read_data_single(idx)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        data = self.read_data(idx)\n",
    "        \n",
    "        sample = {'image': data[0],\n",
    "                  'timestamp': data[1],\n",
    "                  'frame_id': data[2],\n",
    "                  'angle': data[3],\n",
    "                  'torque': data[4],\n",
    "                  'speed': data[5]}\n",
    "        \n",
    "        del data\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Batch with consecutive frames taken from input data\n",
    "\n",
    "from torch.utils.data import Sampler\n",
    "import random\n",
    "\n",
    "class ConsecutiveBatchSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, data_source, batch_size, seq_len, drop_last=False, shuffle=True):\n",
    "        r\"\"\" Sampler to generate consecutive Batches\n",
    "        \n",
    "        Args:\n",
    "            data_source: Source of data\n",
    "            batch_size: Size of batch\n",
    "            seq_len: Number of frames in each sequence (used for context for prediction)\n",
    "            drop: Wether to drop the last incomplete batch\n",
    "            shuffle: Wether to shuffle the data\n",
    "        Return:\n",
    "            List of iterators, size: [batch_size x seq_len x n_channels x height x width]\n",
    "        \"\"\"\n",
    "        super().__init__(data_source)\n",
    "        \n",
    "        self.data_source = data_source\n",
    "        \n",
    "        assert seq_len >= 1, \"Invalid batch size: {}\".format(seq_len)\n",
    "        self.seq_len = seq_len\n",
    "        self.drop_last = drop_last\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        data_size = len(self.data_source)\n",
    "        start_indices = list(range(data_size))\n",
    "        if self.shuffle:\n",
    "            random.shuffle(start_indices)\n",
    "        \n",
    "        batch = []\n",
    "        for idx, ind in enumerate(start_indices):\n",
    "            if data_size - idx < self.batch_size and self.drop_last: # if last batch\n",
    "                break\n",
    "                \n",
    "            seq = []\n",
    "            if ind + 1 < self.seq_len:\n",
    "                seq.extend([0]*(self.seq_len - ind - 1) + list(range(0, ind+1)))\n",
    "            else:\n",
    "                seq.extend(list(range(ind-self.seq_len+1, ind+1)))\n",
    "            \n",
    "            batch.append(seq)\n",
    "            \n",
    "            if len(batch) == self.batch_size or idx == data_size - 1:\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        length = len(self.data_source)\n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        if length % batch_size == 0 or self.drop_last:\n",
    "            return length // batch_size\n",
    "        \n",
    "        return length // batch_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(sample):\n",
    "    r\"\"\" Helper function for (batch) sample visualization\n",
    "    \n",
    "    Args:\n",
    "        sample: Dictionary\n",
    "    \"\"\"\n",
    "    image_dims = len(sample['image'].shape)\n",
    "    assert image_dims <= 5, \"Unsupported image shape: {}\".format(sample['image'].shape)\n",
    "    if image_dims == 3:\n",
    "        plt.imshow(sample['image'])\n",
    "    else:\n",
    "        n0 = sample['image'].shape[0]\n",
    "        n1 = sample['image'].shape[1] if image_dims == 5 else 1\n",
    "        images_flattened = torch.flatten(sample['image'], end_dim=-4)\n",
    "        fig, ax = plt.subplots(n0, n1, figsize=(25, 15))\n",
    "        for i1 in range(n1):\n",
    "            for i0 in range(n0):\n",
    "                image = images_flattened[i0 * n1 + i1]\n",
    "                axis = ax[i0, i1]\n",
    "                axis.imshow(image.permute(1,2,0))\n",
    "                axis.axis('off')\n",
    "                axis.set_title(\"t={}\".format(sample['timestamp'][i0][i1]))\n",
    "                axis.text(10, 30, sample['frame_id'][i0][i1], color='red')\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    \n",
    "    # Your code here...\n",
    "    \n",
    "    del sample_batched # release image to save memory space\n",
    "    \n",
    "    if i_batch == 2: # test loading 10 datapoints\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D CNN with residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# helper function to determine dimension after convolution\n",
    "def conv_output_shape(in_dimension, kernel_size, stride):\n",
    "    output_dim = []\n",
    "    for (in_dim, kern_size, strd) in zip(in_dimension, kernel_size, stride):\n",
    "        len = int(float(in_dim - kern_size) / strd + 1.)\n",
    "        output_dim.append(len)\n",
    "    \n",
    "    return output_dim\n",
    "\n",
    "        \n",
    "class TemporalCNN(nn.Module):\n",
    "    \n",
    "    def _conv_unit(self, in_channels, out_channels, in_shape, kernel_size, stride, dropout_prob):\n",
    "        r\"\"\" Return one 3D convolution unit\n",
    "        \n",
    "        Args:\n",
    "            in_channels: Input channels of the Conv3D module\n",
    "            out_channels: Output channels of the Conv3D module\n",
    "            in_shape: Shape of the input image. i.e. The last 3 dimensions of the input tensor: D x H x W\n",
    "            kernel_size: Kernel size\n",
    "            stride: Stride\n",
    "            dropout_prob: Probability of dropout layer\n",
    "                         \n",
    "        Output:\n",
    "            (conv_module, aux_module, out_shape)\n",
    "        \"\"\"\n",
    "        \n",
    "        conv = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "        dropout = nn.Dropout3d(p=dropout_prob)\n",
    "        conv_module = nn.Sequential(conv, dropout)\n",
    "        out_shape = conv_output_shape(in_shape, kernel_size, stride)\n",
    "        \n",
    "        flatten = nn.Flatten(start_dim=2)\n",
    "        aux = nn.Linear(in_features=np.prod(out_shape[-2:])*out_channels, out_features=128)\n",
    "        aux_module = nn.Sequential(flatten, aux)\n",
    "        \n",
    "        return conv_module, aux_module, out_shape\n",
    "    \n",
    "    def _linear_unit(self, in_features, out_features, dropout_prob):\n",
    "        linear = nn.Linear(in_features, out_features)\n",
    "        dropout = nn.Dropout(p=dropout_prob)\n",
    "        return nn.Sequential(linear, dropout), out_features\n",
    "        \n",
    "    \n",
    "    def __init__(self, in_height, in_width, seq_len, dropout_prob=0.5, aux_history=10):\n",
    "        r\"\"\" TemporalCNN: this model does 3D convolution on the H, W and temporal dimension\n",
    "             It also includes residual connection from each Conv3D output to the final output\n",
    "             \n",
    "             Args:\n",
    "                 in_height: image height\n",
    "                 in_width: image width\n",
    "                 seq_len: image sequence length\n",
    "                 dropout_prob: prob for the dropout layer\n",
    "                 aux_history: length of history to extract from seq_len\n",
    "             \n",
    "             Output:\n",
    "                 nn.Module, accepts input with shape [batch_len, seq_len, C, in_height, in_width]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq_len_ = seq_len\n",
    "        self.in_width_ = in_width\n",
    "        self.in_height_ = in_height\n",
    "        self.aux_history_ = aux_history\n",
    "        in_shape = (seq_len, in_height, in_width)\n",
    "        \n",
    "        conv_layers = []\n",
    "        # conv1\n",
    "        conv, aux, out_shape = self._conv_unit(3, 64, in_shape, (3, 12, 12), (1, 6, 6), dropout_prob)\n",
    "        conv_layers.append((conv, aux))\n",
    "        # conv2\n",
    "        conv, aux, out_shape = self._conv_unit(64, 64, out_shape, (2, 5, 5), (1, 2, 2), dropout_prob)\n",
    "        conv_layers.append((conv, aux))\n",
    "        # conv3\n",
    "        conv, aux, out_shape = self._conv_unit(64, 64, out_shape, (2, 5, 5), (1, 1, 1), dropout_prob)\n",
    "        conv_layers.append((conv, aux))\n",
    "        # conv4\n",
    "        conv, aux, out_shape = self._conv_unit(64, 64, out_shape, (2, 5, 5), (1, 1, 1), dropout_prob)\n",
    "        conv_layers.append((conv, aux))\n",
    "        \n",
    "        linear_layers = []\n",
    "        # Flatten the last 3 dims\n",
    "        flatten = nn.Flatten(start_dim=2)\n",
    "        linear_layers.append(flatten)\n",
    "        # FC 1024\n",
    "        linear, out_features = self._linear_unit(64*np.prod(out_shape[-2:]), 1024, dropout_prob)\n",
    "        linear_layers.append(linear)\n",
    "        # FC 512\n",
    "        linear, out_features = self._linear_unit(out_features, 512, dropout_prob)\n",
    "        linear_layers.append(linear)\n",
    "        # FC 256\n",
    "        linear, out_features = self._linear_unit(out_features, 256, dropout_prob)\n",
    "        linear_layers.append(linear)\n",
    "        # FC 128\n",
    "        linear, out_features = self._linear_unit(out_features, 128, dropout_prob)\n",
    "        linear_layers.append(linear)\n",
    "        \n",
    "        self.conv_layers_ = conv_layers\n",
    "        self.linear_layers_ = linear_layers\n",
    "        self.final_elu_ = nn.ELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute([0, 2, 1, 3, 4]) # swap channel and seq_len, 3D conv over seq_len as depth channel\n",
    "                                       # now: [batch_size, channel, seq_len, H, W]\n",
    "        \n",
    "        aux_outputs = []\n",
    "        for layer in self.conv_layers_:\n",
    "            x_out = layer[0](x)\n",
    "            x_out_permuted = x_out.permute([0, 2, 1, 3, 4]) # swap back for calculation of aux output\n",
    "            x_aux = layer[1](x_out_permuted[:,-self.aux_history_:,:,:,:])\n",
    "#             print(x_out.shape)\n",
    "#             print(x_aux.shape)\n",
    "            aux_outputs.append(x_aux)\n",
    "            x = x_out\n",
    "        \n",
    "        x = x.permute([0, 2, 1, 3, 4]) # swap back the dimensions, now: [batch_size, seq_len, channel, H, W]\n",
    "        for layer in self.linear_layers_:\n",
    "            x = layer(x)\n",
    "        \n",
    "        final_out = x\n",
    "        for aux_out in aux_outputs:\n",
    "            final_out = final_out + aux_out\n",
    "        final_out = self.final_elu_(final_out)\n",
    "#         print(final_out.shape)\n",
    "        \n",
    "        return final_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoregressive LSTM Module\n",
    "\n",
    "class AutoregressiveLSTMCell(nn.Module):\n",
    "    \n",
    "    def __init__(self, target_size, visual_feature_size, hidden_size):\n",
    "        r\"\"\" AutoregressiveModule takes visual feature from 3D CNN module, pass it\n",
    "             first into an internal LSTM cell and then into a Linear network. The final\n",
    "             output of this module is of dimension output_size.\n",
    "             \n",
    "             Args:\n",
    "                 target_dim: dimsion of target value. for this application 3 (angle, speed, torque)\n",
    "                 visual_feature_dim:\n",
    "                 output_size: output size after the Linear network\n",
    "                 autoregressive_mode: wether this module work as autoregressive mode or\n",
    "                     just pass the ground truth to output\n",
    "             Output:\n",
    "                 nn.Module\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.target_size_ = target_size\n",
    "        self.visual_feature_size_ = visual_feature_size\n",
    "        self.hidden_size_ = hidden_size\n",
    "        \n",
    "        self.lstm_cell_ = nn.LSTMCell(input_size=target_size+visual_feature_size, hidden_size=hidden_size)\n",
    "        self.linear_ = nn.Linear(in_features=hidden_size+visual_feature_size+target_size, out_features=target_size)\n",
    "    \n",
    "    def forward(self, visual_features, prev_target, prev_states):\n",
    "        r\"\"\"\n",
    "            Output:\n",
    "                (output, target_ground_truth) for autoregressive_mode = True\n",
    "                (output, (output, ))\n",
    "        \"\"\"\n",
    "        lstm_input = torch.cat((visual_features, prev_target), dim=-1)\n",
    "        h_t, c_t = self.lstm_cell_(lstm_input, prev_states)\n",
    "        linear_input = torch.cat((visual_features, prev_target, h_t), dim=-1)\n",
    "        output = self.linear_(linear_input)\n",
    "        new_state = (h_t, c_t)\n",
    "        \n",
    "        return output, new_state\n",
    "        \n",
    "class AutoregressiveLSTM(AutoregressiveLSTMCell):\n",
    "    \n",
    "    def __init__(self, target_size, visual_feature_size, hidden_size, autoregressive_mode=True):\n",
    "        super().__init__(target_size, visual_feature_size, hidden_size)\n",
    "        self.autoregressive_mode_ = autoregressive_mode\n",
    "    \n",
    "    def forward(self, visual_features, init_target=None, init_states=None, target_groundtruth=None):\n",
    "        # different from LSTM in torch library, we use the second dimension for sequence!\n",
    "        assert self.autoregressive_mode_ or target_groundtruth is not None\n",
    "        \n",
    "        seq_len = visual_features.shape[1]\n",
    "        batch_len = visual_features.shape[0]\n",
    "\n",
    "        prev_target = torch.zeros(batch_len, self.target_size_) if init_target is None else init_target\n",
    "        prev_states = (torch.zeros(batch_len, self.hidden_size_), torch.zeros(batch_len, self.hidden_size_)) if init_states is None else init_states\n",
    "        \n",
    "        outputs = []\n",
    "        states = []\n",
    "        for seq_idx in range(seq_len):\n",
    "            target, state = super().forward(visual_features[:, seq_idx, :], prev_target, prev_states)\n",
    "            prev_target = target if self.autoregressive_mode_ else target_groundtruth[:, seq_idx, :]\n",
    "            outputs.append(target)\n",
    "            states.append(torch.stack(state))\n",
    "            \n",
    "        outputs = torch.stack(outputs)\n",
    "        outputs = outputs.permute(1, 0, 2)  # dim: [batch, seq, target_size]\n",
    "        states = torch.stack(states)\n",
    "        states = states.permute(1, 2, 0, 3) # dim: [ [batch, seq, internal_size], [batch, seq, internal_size] ]\n",
    "        \n",
    "        return outputs, states\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteerNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_cnn_ = TemporalCNN(in_height=480, in_width=640, seq_len=15, dropout_prob=1.0, aux_history=10)\n",
    "        self.model_lstm_gt_ = AutoregressiveLSTM(target_size=3, visual_feature_size=128, hidden_size=64, autoregressive_mode=False)\n",
    "        self.model_lstm_autoreg_ = AutoregressiveLSTM(target_size=3, visual_feature_size=128, hidden_size=64, autoregressive_mode=True)\n",
    "        self.lstm_state_ = None\n",
    "        \n",
    "        self.train = True\n",
    "    \n",
    "    def forward(self, images, target=None):\n",
    "        assert target is None or self.train==True\n",
    "        \n",
    "        features = self.model_cnn_(images)\n",
    "        \n",
    "        if self.lstm_state_ is None:\n",
    "            if self.train:\n",
    "                out_gt, state_gt = self.model_lstm_gt_(features, target_groundtruth=target)\n",
    "            out_autoreg, state_autoreg = self.model_lstm_autoreg_(features)\n",
    "        else:\n",
    "            state_autoreg = self.lstm_state_\n",
    "            state_gt = (state_autoreg[0].clone().detach(),\n",
    "                        state_autoreg[1].clone().detach()) # copies the state. we don't opzimize the state of this LSTM with groundtruth input!\n",
    "            if self.train:\n",
    "                out_gt, _ = self.model_lstm_gt_(features, init_states=state_gt, target_groundtruth=target)\n",
    "            out_autoreg, state_autoreg = self.model_lstm_autoreg_(features, init_states=state_autoreg)\n",
    "        if self.train:\n",
    "            self.lstm_state_ = (state_autoreg[0][-1].detach(), state_autoreg[1][-1].detach())\n",
    "        \n",
    "        return (out_autoreg, out_gt) if self.train else out_autoreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing DataLoader\n",
    "# Warning: this only need to be done once to reduce system overhead (leaking memory)\n",
    "\n",
    "from torch.utils.data import BatchSampler, SequentialSampler, RandomSampler\n",
    "\n",
    "udacity_dataset = UdacityDataset(csv_file='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/interpolated.csv',\n",
    "                                 root_dir='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/',\n",
    "                                 transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                                 select_camera='center_camera')\n",
    "\n",
    "cbs = ConsecutiveBatchSampler(data_source=udacity_dataset, batch_size=20, shuffle=True, drop_last=False, seq_len=15)\n",
    "dataloader = DataLoader(udacity_dataset, sampler=cbs, collate_fn=(lambda x: x[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 270\n",
      "size of validation set: 68\n"
     ]
    }
   ],
   "source": [
    "# train - validation split\n",
    "\n",
    "dataset_size = int(len(udacity_dataset) * 0.01)\n",
    "split_point = int(dataset_size * 0.8)\n",
    "training_set = UdacityDataset(csv_file='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/interpolated.csv',\n",
    "                              root_dir='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/',\n",
    "                              transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                              select_camera='center_camera',\n",
    "                              select_range=(0, split_point))\n",
    "validation_set = UdacityDataset(csv_file='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/interpolated.csv',\n",
    "                                root_dir='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/',\n",
    "                                transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                                select_camera='center_camera',\n",
    "                                select_range=(split_point, dataset_size))\n",
    "\n",
    "print(\"size of training set: {}\".format(len(training_set)))\n",
    "print(\"size of validation set: {}\".format(len(validation_set)))\n",
    "\n",
    "cbs_train = ConsecutiveBatchSampler(data_source=training_set, batch_size=10, shuffle=True, drop_last=True, seq_len=15)\n",
    "cbs_valid = ConsecutiveBatchSampler(data_source=validation_set, batch_size=10, shuffle=True, drop_last=True, seq_len=15)\n",
    "\n",
    "trainig_loader = DataLoader(training_set, sampler=cbs_train, collate_fn=(lambda x: x[0]))\n",
    "validation_loader = DataLoader(validation_set, sampler=cbs_valid, collate_fn=(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steernet = SteerNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(steernet.parameters())\n",
    "\n",
    "def do_epoch():\n",
    "    \n",
    "    # training\n",
    "    steernet.train = True\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, sample in enumerate(trainig_loader):\n",
    "        images = sample['image']\n",
    "        angle = sample['angle'][:, -10:]\n",
    "        torque = sample['torque'][:, -10:]\n",
    "        speed = sample['speed'][:, -10:]\n",
    "        target = torch.stack([angle, torque, speed])\n",
    "        target = target.permute([2, 1, 0]) # (batch_size x seq_len x target_dim)\n",
    "        del sample, torque, speed\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out_autoreg, out_gt = steernet(images, target)\n",
    "        out_autoreg_angle = out_autoreg[:, :, 0]\n",
    "        \n",
    "        loss_angle = criterion(angle, out_autoreg_angle)\n",
    "        loss_autoreg = criterion(out_autoreg, target)\n",
    "        loss_gt = criterion(out_gt, target)\n",
    "        \n",
    "        loss_total = loss_angle + do_epoch.loss_target_weight * (loss_autoreg + loss_gt)\n",
    "        loss_total.backward()\n",
    "        \n",
    "        print(\"it: {} loss_total: {} loss_angle: {} loss_autoreg: {} loss_gt: {}\".format(i, loss_total.item(), loss_angle.item(), loss_autoreg.item(), loss_gt.item()))\n",
    "        optimizer.step()\n",
    "        running_loss += loss_total.item()\n",
    "\n",
    "    print(\"Finished training.\")\n",
    "    \n",
    "    # validation\n",
    "    \n",
    "    with torch.no_grad(): # we don't require grad calcualation in the validation phase. it saves memory.\n",
    "        steernet.train = False\n",
    "\n",
    "        for i, sample in enumerate(validation_loader):\n",
    "            images = sample['image']\n",
    "            angle = sample['angle'][:, -10:]\n",
    "            torque = sample['torque'][:, -10:]\n",
    "            speed = sample['speed'][:, -10:]\n",
    "            target = torch.stack([angle, torque, speed])\n",
    "            target = target.permute([2, 1, 0]) # (batch_size x seq_len x target_dim)\n",
    "            del sample, torque, speed\n",
    "\n",
    "            out_autoreg = steernet(images)\n",
    "            out_autoreg_angle = out_autoreg[:, :, 0]\n",
    "\n",
    "            loss_angle = criterion(angle, out_autoreg_angle)\n",
    "            loss_autoreg = criterion(out_autoreg, target)\n",
    "\n",
    "            print(\"it: {} loss_angle: {} loss_autoreg: {}\".format(i, loss_angle.item(), loss_autoreg.item()))\n",
    "                  \n",
    "    print(\"Finished validation\")\n",
    "    \n",
    "do_epoch.loss_target_weight = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 0 loss_total: 33.19867706298828 loss_angle: 0.008617046289145947 loss_autoreg: 174.0677947998047 loss_gt: 157.832763671875\n",
      "it: 1 loss_total: 32.897132873535156 loss_angle: 0.010810041800141335 loss_autoreg: 172.77401733398438 loss_gt: 156.0891876220703\n",
      "it: 2 loss_total: 33.01936721801758 loss_angle: 0.007988323457539082 loss_autoreg: 173.67132568359375 loss_gt: 156.4424285888672\n",
      "it: 3 loss_total: 32.9239616394043 loss_angle: 0.009369692765176296 loss_autoreg: 173.47828674316406 loss_gt: 155.66766357421875\n",
      "it: 4 loss_total: 32.86370849609375 loss_angle: 0.0054670716635882854 loss_autoreg: 173.3343963623047 loss_gt: 155.2480010986328\n",
      "it: 5 loss_total: 32.86917495727539 loss_angle: 0.005387292709201574 loss_autoreg: 173.64503479003906 loss_gt: 154.99285888671875\n",
      "it: 6 loss_total: 32.786033630371094 loss_angle: 0.0036986633203923702 loss_autoreg: 173.49441528320312 loss_gt: 154.32891845703125\n",
      "it: 7 loss_total: 33.14338302612305 loss_angle: 0.002446686616167426 loss_autoreg: 175.55491638183594 loss_gt: 155.8544464111328\n",
      "it: 8 loss_total: 33.56192398071289 loss_angle: 0.0007394293206743896 loss_autoreg: 178.03099060058594 loss_gt: 157.58082580566406\n",
      "it: 9 loss_total: 32.97202682495117 loss_angle: 0.0012166679371148348 loss_autoreg: 175.0749969482422 loss_gt: 154.6331024169922\n",
      "it: 10 loss_total: 32.025482177734375 loss_angle: 0.004411710891872644 loss_autoreg: 170.42796325683594 loss_gt: 149.78274536132812\n",
      "it: 11 loss_total: 32.69598388671875 loss_angle: 0.0021473949309438467 loss_autoreg: 174.23020935058594 loss_gt: 152.7081298828125\n",
      "it: 12 loss_total: 32.36343765258789 loss_angle: 0.002632425632327795 loss_autoreg: 172.69154357910156 loss_gt: 150.91650390625\n",
      "it: 13 loss_total: 31.5260066986084 loss_angle: 0.006822689902037382 loss_autoreg: 168.38967895507812 loss_gt: 146.80215454101562\n",
      "it: 14 loss_total: 31.845033645629883 loss_angle: 0.003541897516697645 loss_autoreg: 170.34739685058594 loss_gt: 148.06753540039062\n",
      "it: 15 loss_total: 32.14221954345703 loss_angle: 0.001451718038879335 loss_autoreg: 172.12240600585938 loss_gt: 149.28526306152344\n",
      "it: 16 loss_total: 32.21440887451172 loss_angle: 0.0028486924711614847 loss_autoreg: 172.7732696533203 loss_gt: 149.34231567382812\n",
      "it: 17 loss_total: 32.477813720703125 loss_angle: 0.0014209140790626407 loss_autoreg: 174.38552856445312 loss_gt: 150.37841796875\n",
      "it: 18 loss_total: 31.458662033081055 loss_angle: 0.0017386011313647032 loss_autoreg: 169.29612731933594 loss_gt: 145.27308654785156\n",
      "it: 19 loss_total: 32.32938766479492 loss_angle: 0.0012584355426952243 loss_autoreg: 173.8618621826172 loss_gt: 149.41941833496094\n",
      "it: 20 loss_total: 31.987422943115234 loss_angle: 0.000878328166436404 loss_autoreg: 172.3947296142578 loss_gt: 147.47071838378906\n",
      "it: 21 loss_total: 31.818683624267578 loss_angle: 0.0014591068029403687 loss_autoreg: 171.599365234375 loss_gt: 146.57286071777344\n",
      "it: 22 loss_total: 31.678754806518555 loss_angle: 0.0015507264761254191 loss_autoreg: 171.1319122314453 loss_gt: 145.64012145996094\n",
      "it: 23 loss_total: 31.45058822631836 loss_angle: 0.0022558108903467655 loss_autoreg: 170.16615295410156 loss_gt: 144.31715393066406\n",
      "it: 24 loss_total: 31.831684112548828 loss_angle: 0.0016605627024546266 loss_autoreg: 172.29275512695312 loss_gt: 146.00746154785156\n",
      "it: 25 loss_total: 31.364816665649414 loss_angle: 0.001644271775148809 loss_autoreg: 169.8328399658203 loss_gt: 143.79885864257812\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.01131243072450161 loss_autoreg: 150.99880981445312\n",
      "it: 1 loss_angle: 0.012384171597659588 loss_autoreg: 153.3126983642578\n",
      "it: 2 loss_angle: 0.012359405867755413 loss_autoreg: 152.43264770507812\n",
      "it: 3 loss_angle: 0.011398817412555218 loss_autoreg: 148.91802978515625\n",
      "it: 4 loss_angle: 0.010600886307656765 loss_autoreg: 149.7559051513672\n",
      "Finished validation\n",
      "it: 0 loss_total: 30.90532684326172 loss_angle: 0.0043992516584694386 loss_autoreg: 167.40696716308594 loss_gt: 141.60231018066406\n",
      "it: 1 loss_total: 30.389175415039062 loss_angle: 0.006616842932999134 loss_autoreg: 164.88258361816406 loss_gt: 138.94300842285156\n",
      "it: 2 loss_total: 30.70668601989746 loss_angle: 0.005205256398767233 loss_autoreg: 166.5933380126953 loss_gt: 140.4214630126953\n",
      "it: 3 loss_total: 30.807085037231445 loss_angle: 0.0023007707204669714 loss_autoreg: 167.03697204589844 loss_gt: 141.01089477539062\n",
      "it: 4 loss_total: 30.17388916015625 loss_angle: 0.0038167345337569714 loss_autoreg: 163.5784454345703 loss_gt: 138.1222686767578\n",
      "it: 5 loss_total: 30.006633758544922 loss_angle: 0.002880013780668378 loss_autoreg: 162.6304473876953 loss_gt: 137.40707397460938\n",
      "it: 6 loss_total: 29.91020393371582 loss_angle: 0.0027201257180422544 loss_autoreg: 161.69630432128906 loss_gt: 137.3785400390625\n",
      "it: 7 loss_total: 29.697568893432617 loss_angle: 0.0017929911846295 loss_autoreg: 160.09144592285156 loss_gt: 136.8663330078125\n",
      "it: 8 loss_total: 28.909212112426758 loss_angle: 0.0010457244934514165 loss_autoreg: 155.31243896484375 loss_gt: 133.7692108154297\n",
      "it: 9 loss_total: 28.196969985961914 loss_angle: 0.002429284853860736 loss_autoreg: 150.72695922851562 loss_gt: 131.21844482421875\n",
      "it: 10 loss_total: 28.13649559020996 loss_angle: 0.001638967078179121 loss_autoreg: 149.80740356445312 loss_gt: 131.5411834716797\n",
      "it: 11 loss_total: 27.39017677307129 loss_angle: 0.0018156669102609158 loss_autoreg: 144.9307098388672 loss_gt: 128.95289611816406\n",
      "it: 12 loss_total: 27.183475494384766 loss_angle: 0.0020392844453454018 loss_autoreg: 143.226318359375 loss_gt: 128.58804321289062\n",
      "it: 13 loss_total: 25.560468673706055 loss_angle: 0.008658535778522491 loss_autoreg: 134.25155639648438 loss_gt: 121.26653289794922\n",
      "it: 14 loss_total: 25.500308990478516 loss_angle: 0.0037664962001144886 loss_autoreg: 133.60520935058594 loss_gt: 121.36022186279297\n",
      "it: 15 loss_total: 25.633045196533203 loss_angle: 0.0009597185417078435 loss_autoreg: 134.11318969726562 loss_gt: 122.20767211914062\n",
      "it: 16 loss_total: 25.08599090576172 loss_angle: 0.001655346481129527 loss_autoreg: 131.01792907714844 loss_gt: 119.82543182373047\n",
      "it: 17 loss_total: 24.537473678588867 loss_angle: 0.0025482408236712217 loss_autoreg: 127.98115539550781 loss_gt: 117.36808776855469\n",
      "it: 18 loss_total: 24.154930114746094 loss_angle: 0.001855743583291769 loss_autoreg: 125.95915222167969 loss_gt: 115.57158660888672\n",
      "it: 19 loss_total: 23.314374923706055 loss_angle: 0.006193071138113737 loss_autoreg: 121.26947784423828 loss_gt: 111.81233215332031\n",
      "it: 20 loss_total: 23.476028442382812 loss_angle: 0.002727474318817258 loss_autoreg: 122.0267562866211 loss_gt: 112.70625305175781\n",
      "it: 21 loss_total: 23.084814071655273 loss_angle: 0.003259646939113736 loss_autoreg: 119.82532501220703 loss_gt: 110.9902114868164\n",
      "it: 22 loss_total: 22.875375747680664 loss_angle: 0.001837060204707086 loss_autoreg: 118.77415466308594 loss_gt: 109.96122741699219\n",
      "it: 23 loss_total: 22.47212028503418 loss_angle: 0.0016564674442633986 loss_autoreg: 116.50202178955078 loss_gt: 108.20263671875\n",
      "it: 24 loss_total: 22.10419273376465 loss_angle: 0.0028113476000726223 loss_autoreg: 114.51148223876953 loss_gt: 106.50232696533203\n",
      "it: 25 loss_total: 22.411645889282227 loss_angle: 0.0008641768363304436 loss_autoreg: 116.06657409667969 loss_gt: 108.0412368774414\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.014442619867622852 loss_autoreg: 97.43766784667969\n",
      "it: 1 loss_angle: 0.015858864411711693 loss_autoreg: 98.5537338256836\n",
      "it: 2 loss_angle: 0.014611145481467247 loss_autoreg: 97.3113784790039\n",
      "it: 3 loss_angle: 0.014231209643185139 loss_autoreg: 95.62289428710938\n",
      "it: 4 loss_angle: 0.014656001701951027 loss_autoreg: 97.92487335205078\n",
      "Finished validation\n",
      "it: 0 loss_total: 21.9110107421875 loss_angle: 0.0025653454940766096 loss_autoreg: 113.36978149414062 loss_gt: 105.71465301513672\n",
      "it: 1 loss_total: 21.011938095092773 loss_angle: 0.005580022465437651 loss_autoreg: 108.4489974975586 loss_gt: 101.61456298828125\n",
      "it: 2 loss_total: 20.73601722717285 loss_angle: 0.003454443532973528 loss_autoreg: 106.99219512939453 loss_gt: 100.33341979980469\n",
      "it: 3 loss_total: 20.613964080810547 loss_angle: 0.0013153908075764775 loss_autoreg: 106.30017852783203 loss_gt: 99.82630157470703\n",
      "it: 4 loss_total: 20.019506454467773 loss_angle: 0.00221472280099988 loss_autoreg: 103.05387878417969 loss_gt: 97.11902618408203\n",
      "it: 5 loss_total: 20.3541202545166 loss_angle: 0.0010588502045720816 loss_autoreg: 104.84642028808594 loss_gt: 98.68418884277344\n",
      "it: 6 loss_total: 19.809364318847656 loss_angle: 0.0021537395659834146 loss_autoreg: 101.93911743164062 loss_gt: 96.13298797607422\n",
      "it: 7 loss_total: 19.39024543762207 loss_angle: 0.003062528558075428 loss_autoreg: 99.62830352783203 loss_gt: 94.24351501464844\n",
      "it: 8 loss_total: 18.656635284423828 loss_angle: 0.006108375266194344 loss_autoreg: 95.69111633300781 loss_gt: 90.81412506103516\n",
      "it: 9 loss_total: 18.84054183959961 loss_angle: 0.0027901725843548775 loss_autoreg: 96.75382995605469 loss_gt: 91.62368774414062\n",
      "it: 10 loss_total: 18.30984115600586 loss_angle: 0.0013703427975997329 loss_autoreg: 93.89102172851562 loss_gt: 89.19369506835938\n",
      "it: 11 loss_total: 17.77895736694336 loss_angle: 0.002509067300707102 loss_autoreg: 91.08443450927734 loss_gt: 86.68006134033203\n",
      "it: 12 loss_total: 17.7572078704834 loss_angle: 0.0022026714868843555 loss_autoreg: 90.94651794433594 loss_gt: 86.60352325439453\n",
      "it: 13 loss_total: 17.37851333618164 loss_angle: 0.001946542994119227 loss_autoreg: 88.95153045654297 loss_gt: 84.81411743164062\n",
      "it: 14 loss_total: 17.493772506713867 loss_angle: 0.0018684550886973739 loss_autoreg: 89.48717498779297 loss_gt: 85.43186950683594\n",
      "it: 15 loss_total: 17.530864715576172 loss_angle: 0.0009292805334553123 loss_autoreg: 89.73155975341797 loss_gt: 85.56778717041016\n",
      "it: 16 loss_total: 16.547130584716797 loss_angle: 0.004010292701423168 loss_autoreg: 84.41817474365234 loss_gt: 81.01301574707031\n",
      "it: 17 loss_total: 16.62162208557129 loss_angle: 0.0033037778921425343 loss_autoreg: 84.89099884033203 loss_gt: 81.29218292236328\n",
      "it: 18 loss_total: 16.250629425048828 loss_angle: 0.002547158859670162 loss_autoreg: 82.9032211303711 loss_gt: 79.57762145996094\n",
      "it: 19 loss_total: 16.489229202270508 loss_angle: 0.0014220471493899822 loss_autoreg: 84.1624526977539 loss_gt: 80.71561431884766\n",
      "it: 20 loss_total: 15.747148513793945 loss_angle: 0.000629973248578608 loss_autoreg: 80.23690032958984 loss_gt: 77.22827911376953\n",
      "it: 21 loss_total: 15.9264554977417 loss_angle: 0.002236534608528018 loss_autoreg: 81.15005493164062 loss_gt: 78.09212493896484\n",
      "it: 22 loss_total: 15.252253532409668 loss_angle: 0.002480515744537115 loss_autoreg: 77.57062530517578 loss_gt: 74.9271011352539\n",
      "it: 23 loss_total: 14.828965187072754 loss_angle: 0.003754250006750226 loss_autoreg: 75.36891174316406 loss_gt: 72.88319396972656\n",
      "it: 24 loss_total: 15.03891372680664 loss_angle: 0.0019928421825170517 loss_autoreg: 76.50636291503906 loss_gt: 73.86284637451172\n",
      "it: 25 loss_total: 14.62014389038086 loss_angle: 0.002414899179711938 loss_autoreg: 74.25570678710938 loss_gt: 71.92158508300781\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.00725801894441247 loss_autoreg: 63.04982376098633\n",
      "it: 1 loss_angle: 0.007208524737507105 loss_autoreg: 62.49351501464844\n",
      "it: 2 loss_angle: 0.007462283596396446 loss_autoreg: 63.0883674621582\n",
      "it: 3 loss_angle: 0.007113856263458729 loss_autoreg: 61.56416702270508\n",
      "it: 4 loss_angle: 0.007102474570274353 loss_autoreg: 62.58575439453125\n",
      "Finished validation\n",
      "it: 0 loss_total: 14.440658569335938 loss_angle: 0.0013439911417663097 loss_autoreg: 73.31559753417969 loss_gt: 71.07754516601562\n",
      "it: 1 loss_total: 14.017123222351074 loss_angle: 0.0038456653710454702 loss_autoreg: 71.09587860107422 loss_gt: 69.03691101074219\n",
      "it: 2 loss_total: 13.96190071105957 loss_angle: 0.0022423460613936186 loss_autoreg: 70.84027862548828 loss_gt: 68.75631713867188\n",
      "it: 3 loss_total: 14.066222190856934 loss_angle: 0.001387450727634132 loss_autoreg: 71.38500213623047 loss_gt: 69.26333618164062\n",
      "it: 4 loss_total: 13.347414016723633 loss_angle: 0.002342646010220051 loss_autoreg: 67.60889434814453 loss_gt: 65.84181213378906\n",
      "it: 5 loss_total: 13.64277172088623 loss_angle: 0.0009538385202176869 loss_autoreg: 69.17595672607422 loss_gt: 67.24222564697266\n",
      "it: 6 loss_total: 13.540228843688965 loss_angle: 0.0010985491098836064 loss_autoreg: 68.6723861694336 loss_gt: 66.71890258789062\n",
      "it: 7 loss_total: 12.704907417297363 loss_angle: 0.005411588586866856 loss_autoreg: 64.2745590209961 loss_gt: 62.72039794921875\n",
      "it: 8 loss_total: 13.240246772766113 loss_angle: 0.0011773447040468454 loss_autoreg: 67.1132583618164 loss_gt: 65.27742767333984\n",
      "it: 9 loss_total: 12.789285659790039 loss_angle: 0.0025169432628899813 loss_autoreg: 64.66033935546875 loss_gt: 63.20735168457031\n",
      "it: 10 loss_total: 12.274435043334961 loss_angle: 0.0020552976056933403 loss_autoreg: 62.023067474365234 loss_gt: 60.70073699951172\n",
      "it: 11 loss_total: 12.198089599609375 loss_angle: 0.001443267217837274 loss_autoreg: 61.707618713378906 loss_gt: 60.25884246826172\n",
      "it: 12 loss_total: 12.185952186584473 loss_angle: 0.0008170633809641004 loss_autoreg: 61.639732360839844 loss_gt: 60.211612701416016\n",
      "it: 13 loss_total: 11.827229499816895 loss_angle: 0.0008359499042853713 loss_autoreg: 59.78860855102539 loss_gt: 58.47532653808594\n",
      "it: 14 loss_total: 12.146445274353027 loss_angle: 0.001115897437557578 loss_autoreg: 61.45451736450195 loss_gt: 59.998775482177734\n",
      "it: 15 loss_total: 11.80041790008545 loss_angle: 0.0017351966816931963 loss_autoreg: 59.575077056884766 loss_gt: 58.41175842285156\n",
      "it: 16 loss_total: 11.667760848999023 loss_angle: 0.003035418689250946 loss_autoreg: 58.8947868347168 loss_gt: 57.75246047973633\n",
      "it: 17 loss_total: 11.341434478759766 loss_angle: 0.003602508222684264 loss_autoreg: 57.19526672363281 loss_gt: 56.183040618896484\n",
      "it: 18 loss_total: 11.000493049621582 loss_angle: 0.00255426112562418 loss_autoreg: 55.44150924682617 loss_gt: 54.537879943847656\n",
      "it: 19 loss_total: 10.745986938476562 loss_angle: 0.002172332489863038 loss_autoreg: 54.060970306396484 loss_gt: 53.37717056274414\n",
      "it: 20 loss_total: 10.960329055786133 loss_angle: 0.00229820073582232 loss_autoreg: 55.19594955444336 loss_gt: 54.38435363769531\n",
      "it: 21 loss_total: 10.720420837402344 loss_angle: 0.003350216429680586 loss_autoreg: 53.938743591308594 loss_gt: 53.231956481933594\n",
      "it: 22 loss_total: 10.298418045043945 loss_angle: 0.002312022028490901 loss_autoreg: 51.69894027709961 loss_gt: 51.262115478515625\n",
      "it: 23 loss_total: 10.242172241210938 loss_angle: 0.002107035368680954 loss_autoreg: 51.47652816772461 loss_gt: 50.924129486083984\n",
      "it: 24 loss_total: 10.064810752868652 loss_angle: 0.0040966602973639965 loss_autoreg: 50.54276657104492 loss_gt: 50.06436538696289\n",
      "it: 25 loss_total: 9.944825172424316 loss_angle: 0.00305061019025743 loss_autoreg: 49.79117202758789 loss_gt: 49.626564025878906\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.009530950337648392 loss_autoreg: 39.936336517333984\n",
      "it: 1 loss_angle: 0.009530902840197086 loss_autoreg: 40.98905944824219\n",
      "it: 2 loss_angle: 0.008871310390532017 loss_autoreg: 40.27788543701172\n",
      "it: 3 loss_angle: 0.007854251191020012 loss_autoreg: 38.60907745361328\n",
      "it: 4 loss_angle: 0.009239358827471733 loss_autoreg: 39.95486068725586\n",
      "Finished validation\n",
      "it: 0 loss_total: 9.793120384216309 loss_angle: 0.0013603422557935119 loss_autoreg: 49.00225067138672 loss_gt: 48.91535568237305\n",
      "it: 1 loss_total: 9.716084480285645 loss_angle: 0.0008020419627428055 loss_autoreg: 48.59193801879883 loss_gt: 48.56088638305664\n",
      "it: 2 loss_total: 9.473967552185059 loss_angle: 0.0022282463032752275 loss_autoreg: 47.28597640991211 loss_gt: 47.43141555786133\n",
      "it: 3 loss_total: 9.576759338378906 loss_angle: 0.001634043175727129 loss_autoreg: 47.843406677246094 loss_gt: 47.90784454345703\n",
      "it: 4 loss_total: 9.423102378845215 loss_angle: 0.001820354606024921 loss_autoreg: 47.091529846191406 loss_gt: 47.12128448486328\n",
      "it: 5 loss_total: 9.339417457580566 loss_angle: 0.0027922485023736954 loss_autoreg: 46.55353927612305 loss_gt: 46.81270980834961\n",
      "it: 6 loss_total: 9.096424102783203 loss_angle: 0.002896309830248356 loss_autoreg: 45.27568435668945 loss_gt: 45.65958786010742\n",
      "it: 7 loss_total: 8.691267013549805 loss_angle: 0.004210697486996651 loss_autoreg: 43.141056060791016 loss_gt: 43.72951126098633\n",
      "it: 8 loss_total: 8.628920555114746 loss_angle: 0.004276810679584742 loss_autoreg: 42.79582595825195 loss_gt: 43.45060729980469\n",
      "it: 9 loss_total: 8.215088844299316 loss_angle: 0.0018609920516610146 loss_autoreg: 40.52601623535156 loss_gt: 41.606266021728516\n",
      "it: 10 loss_total: 8.418353080749512 loss_angle: 0.0011655964190140367 loss_autoreg: 41.634517669677734 loss_gt: 42.537357330322266\n",
      "it: 11 loss_total: 8.2655668258667 loss_angle: 0.002978864824399352 loss_autoreg: 40.853126525878906 loss_gt: 41.77273941040039\n",
      "it: 12 loss_total: 7.837784767150879 loss_angle: 0.0027078664861619473 loss_autoreg: 38.599021911621094 loss_gt: 39.75175094604492\n",
      "it: 13 loss_total: 8.163773536682129 loss_angle: 0.0031031605321913958 loss_autoreg: 40.21250915527344 loss_gt: 41.39419174194336\n",
      "it: 14 loss_total: 7.773853778839111 loss_angle: 0.0020564270671457052 loss_autoreg: 38.125953674316406 loss_gt: 39.59202194213867\n",
      "it: 15 loss_total: 7.694252014160156 loss_angle: 0.0022848504595458508 loss_autoreg: 37.71794509887695 loss_gt: 39.201725006103516\n",
      "it: 16 loss_total: 7.417164325714111 loss_angle: 0.005364036653190851 loss_autoreg: 36.2292594909668 loss_gt: 37.88874435424805\n",
      "it: 17 loss_total: 7.448227882385254 loss_angle: 0.002087872475385666 loss_autoreg: 36.46416091918945 loss_gt: 37.99723434448242\n",
      "it: 18 loss_total: 7.105337142944336 loss_angle: 0.002252676524221897 loss_autoreg: 34.63008499145508 loss_gt: 36.400760650634766\n",
      "it: 19 loss_total: 7.242908954620361 loss_angle: 0.002932662609964609 loss_autoreg: 35.32598114013672 loss_gt: 37.073787689208984\n",
      "it: 20 loss_total: 7.275991439819336 loss_angle: 0.002082391642034054 loss_autoreg: 35.460018157958984 loss_gt: 37.279075622558594\n",
      "it: 21 loss_total: 6.89656925201416 loss_angle: 0.0026982033159583807 loss_autoreg: 33.44915771484375 loss_gt: 35.48955154418945\n",
      "it: 22 loss_total: 7.071793556213379 loss_angle: 0.00186285434756428 loss_autoreg: 34.4919548034668 loss_gt: 36.20734786987305\n",
      "it: 23 loss_total: 7.1065354347229 loss_angle: 0.0015897637931630015 loss_autoreg: 34.609519958496094 loss_gt: 36.43993377685547\n",
      "it: 24 loss_total: 6.950537204742432 loss_angle: 0.0009917067363858223 loss_autoreg: 33.717281341552734 loss_gt: 35.778175354003906\n",
      "it: 25 loss_total: 6.734313488006592 loss_angle: 0.002856585429981351 loss_autoreg: 32.556724548339844 loss_gt: 34.757843017578125\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.015320487320423126 loss_autoreg: 25.127866744995117\n",
      "it: 1 loss_angle: 0.011455487459897995 loss_autoreg: 23.888093948364258\n",
      "it: 2 loss_angle: 0.013078026473522186 loss_autoreg: 23.409870147705078\n",
      "it: 3 loss_angle: 0.013344747945666313 loss_autoreg: 23.883649826049805\n",
      "it: 4 loss_angle: 0.013913107104599476 loss_autoreg: 24.689409255981445\n",
      "Finished validation\n",
      "it: 0 loss_total: 6.879118919372559 loss_angle: 0.0008299287292174995 loss_autoreg: 33.35063934326172 loss_gt: 35.4322509765625\n",
      "it: 1 loss_total: 6.642025947570801 loss_angle: 0.0011124678421765566 loss_autoreg: 32.02920150756836 loss_gt: 34.37992858886719\n",
      "it: 2 loss_total: 6.506411552429199 loss_angle: 0.0008195905247703195 loss_autoreg: 31.30653953552246 loss_gt: 33.74937438964844\n",
      "it: 3 loss_total: 6.300309181213379 loss_angle: 0.0012184599181637168 loss_autoreg: 30.3098087310791 loss_gt: 32.681095123291016\n",
      "it: 4 loss_total: 5.9057416915893555 loss_angle: 0.0025898150634020567 loss_autoreg: 28.166702270507812 loss_gt: 30.864818572998047\n",
      "it: 5 loss_total: 5.914303779602051 loss_angle: 0.002273861551657319 loss_autoreg: 28.159963607788086 loss_gt: 30.9603328704834\n",
      "it: 6 loss_total: 6.101436614990234 loss_angle: 0.004036608152091503 loss_autoreg: 29.18951416015625 loss_gt: 31.784488677978516\n",
      "it: 7 loss_total: 5.751622200012207 loss_angle: 0.0027350103482604027 loss_autoreg: 27.355995178222656 loss_gt: 30.132871627807617\n",
      "it: 8 loss_total: 5.622389316558838 loss_angle: 0.001891551655717194 loss_autoreg: 26.655479431152344 loss_gt: 29.549495697021484\n",
      "it: 9 loss_total: 5.618433952331543 loss_angle: 0.0014983245637267828 loss_autoreg: 26.5743465423584 loss_gt: 29.595008850097656\n",
      "it: 10 loss_total: 5.591383934020996 loss_angle: 0.0023347469978034496 loss_autoreg: 26.4345760345459 loss_gt: 29.455915451049805\n",
      "it: 11 loss_total: 5.527428150177002 loss_angle: 0.0007840725011192262 loss_autoreg: 26.09589195251465 loss_gt: 29.170547485351562\n",
      "it: 12 loss_total: 5.287469863891602 loss_angle: 0.0031849972438067198 loss_autoreg: 24.772310256958008 loss_gt: 28.070539474487305\n",
      "it: 13 loss_total: 4.987211227416992 loss_angle: 0.003840157762169838 loss_autoreg: 23.18198585510254 loss_gt: 26.651721954345703\n",
      "it: 14 loss_total: 5.123436450958252 loss_angle: 0.0020969624165445566 loss_autoreg: 23.931095123291016 loss_gt: 27.282299041748047\n",
      "it: 15 loss_total: 5.06667423248291 loss_angle: 0.002064730040729046 loss_autoreg: 23.581653594970703 loss_gt: 27.064441680908203\n",
      "it: 16 loss_total: 4.793483734130859 loss_angle: 0.003305679652839899 loss_autoreg: 22.233238220214844 loss_gt: 25.668540954589844\n",
      "it: 17 loss_total: 5.140960693359375 loss_angle: 0.004621000960469246 loss_autoreg: 24.01055145263672 loss_gt: 27.35284423828125\n",
      "it: 18 loss_total: 4.564756393432617 loss_angle: 0.0022072885185480118 loss_autoreg: 20.9720401763916 loss_gt: 24.65345001220703\n",
      "it: 19 loss_total: 4.9096150398254395 loss_angle: 0.00183460908010602 loss_autoreg: 22.77685546875 loss_gt: 26.300947189331055\n",
      "it: 20 loss_total: 4.5701799392700195 loss_angle: 0.002094205468893051 loss_autoreg: 21.007343292236328 loss_gt: 24.673511505126953\n",
      "it: 21 loss_total: 4.401236534118652 loss_angle: 0.00407374557107687 loss_autoreg: 20.118072509765625 loss_gt: 23.853553771972656\n",
      "it: 22 loss_total: 4.305014133453369 loss_angle: 0.0024019666016101837 loss_autoreg: 19.583032608032227 loss_gt: 23.443090438842773\n",
      "it: 23 loss_total: 4.410532474517822 loss_angle: 0.0025280790869146585 loss_autoreg: 20.079744338989258 loss_gt: 24.000293731689453\n",
      "it: 24 loss_total: 4.131831645965576 loss_angle: 0.0022436147555708885 loss_autoreg: 18.729610443115234 loss_gt: 22.566268920898438\n",
      "it: 25 loss_total: 4.240862846374512 loss_angle: 0.0016407661605626345 loss_autoreg: 19.19033432006836 loss_gt: 23.201885223388672\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.0016715623205527663 loss_autoreg: 12.543121337890625\n",
      "it: 1 loss_angle: 0.0019333059899508953 loss_autoreg: 13.537287712097168\n",
      "it: 2 loss_angle: 0.0019592440221458673 loss_autoreg: 13.679012298583984\n",
      "it: 3 loss_angle: 0.0023354932200163603 loss_autoreg: 13.894195556640625\n",
      "it: 4 loss_angle: 0.002488938858732581 loss_autoreg: 14.169426918029785\n",
      "Finished validation\n",
      "it: 0 loss_total: 4.157750606536865 loss_angle: 0.0023232053499668837 loss_autoreg: 18.75258445739746 loss_gt: 22.80169105529785\n",
      "it: 1 loss_total: 4.122223854064941 loss_angle: 0.0026504695415496826 loss_autoreg: 18.49517250061035 loss_gt: 22.700563430786133\n",
      "it: 2 loss_total: 4.141290664672852 loss_angle: 0.003744373330846429 loss_autoreg: 18.642839431762695 loss_gt: 22.73261833190918\n",
      "it: 3 loss_total: 3.959827184677124 loss_angle: 0.0019215410575270653 loss_autoreg: 17.732614517211914 loss_gt: 21.8464412689209\n",
      "it: 4 loss_total: 3.814970016479492 loss_angle: 0.0026957059744745493 loss_autoreg: 16.926740646362305 loss_gt: 21.196001052856445\n",
      "it: 5 loss_total: 3.7806625366210938 loss_angle: 0.0015404614387080073 loss_autoreg: 16.726587295532227 loss_gt: 21.06463623046875\n",
      "it: 6 loss_total: 3.86350679397583 loss_angle: 0.0010297868866473436 loss_autoreg: 17.18020248413086 loss_gt: 21.44456672668457\n",
      "it: 7 loss_total: 3.6769299507141113 loss_angle: 0.0029238646384328604 loss_autoreg: 16.152841567993164 loss_gt: 20.58721923828125\n",
      "it: 8 loss_total: 3.6367011070251465 loss_angle: 0.0009812325006350875 loss_autoreg: 15.96520709991455 loss_gt: 20.391990661621094\n",
      "it: 9 loss_total: 3.5625269412994385 loss_angle: 0.002315388759598136 loss_autoreg: 15.635968208312988 loss_gt: 19.966148376464844\n",
      "it: 10 loss_total: 3.5198638439178467 loss_angle: 0.0015166167868301272 loss_autoreg: 15.378931999206543 loss_gt: 19.804540634155273\n",
      "it: 11 loss_total: 3.1502130031585693 loss_angle: 0.002041272819042206 loss_autoreg: 13.473943710327148 loss_gt: 18.00777244567871\n",
      "it: 12 loss_total: 3.359229326248169 loss_angle: 0.0021805008873343468 loss_autoreg: 14.506389617919922 loss_gt: 19.064096450805664\n",
      "it: 13 loss_total: 3.256890296936035 loss_angle: 0.001863919198513031 loss_autoreg: 13.954654693603516 loss_gt: 18.595609664916992\n",
      "it: 14 loss_total: 3.3148341178894043 loss_angle: 0.0013741094153374434 loss_autoreg: 14.229155540466309 loss_gt: 18.905445098876953\n",
      "it: 15 loss_total: 3.3951833248138428 loss_angle: 0.0016218109522014856 loss_autoreg: 14.655556678771973 loss_gt: 19.280057907104492\n",
      "it: 16 loss_total: 2.906243085861206 loss_angle: 0.003477955237030983 loss_autoreg: 12.167645454406738 loss_gt: 16.860002517700195\n",
      "it: 17 loss_total: 3.086148977279663 loss_angle: 0.0012435177341103554 loss_autoreg: 13.015267372131348 loss_gt: 17.833786010742188\n",
      "it: 18 loss_total: 3.160794734954834 loss_angle: 0.0022637383081018925 loss_autoreg: 13.43542766571045 loss_gt: 18.149879455566406\n",
      "it: 19 loss_total: 3.047271490097046 loss_angle: 0.0006089620874263346 loss_autoreg: 12.825119972229004 loss_gt: 17.641504287719727\n",
      "it: 20 loss_total: 2.662733793258667 loss_angle: 0.0019642403349280357 loss_autoreg: 10.92141056060791 loss_gt: 15.686284065246582\n",
      "it: 21 loss_total: 2.992591142654419 loss_angle: 0.0030036773532629013 loss_autoreg: 12.553744316101074 loss_gt: 17.342130661010742\n",
      "it: 22 loss_total: 2.8192174434661865 loss_angle: 0.0021677836775779724 loss_autoreg: 11.69421672821045 loss_gt: 16.476282119750977\n",
      "it: 23 loss_total: 2.762608289718628 loss_angle: 0.0016913891304284334 loss_autoreg: 11.403878211975098 loss_gt: 16.205291748046875\n",
      "it: 24 loss_total: 2.7073118686676025 loss_angle: 0.001309789135120809 loss_autoreg: 11.086047172546387 loss_gt: 15.973973274230957\n",
      "it: 25 loss_total: 2.619264602661133 loss_angle: 0.0021228797268122435 loss_autoreg: 10.65173625946045 loss_gt: 15.519680976867676\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.005881468765437603 loss_autoreg: 6.691213130950928\n",
      "it: 1 loss_angle: 0.006309730466455221 loss_autoreg: 6.913819789886475\n",
      "it: 2 loss_angle: 0.0058227707631886005 loss_autoreg: 6.964741230010986\n",
      "it: 3 loss_angle: 0.005667800083756447 loss_autoreg: 6.6590118408203125\n",
      "it: 4 loss_angle: 0.005991841666400433 loss_autoreg: 7.024766445159912\n",
      "Finished validation\n",
      "it: 0 loss_total: 2.6566078662872314 loss_angle: 0.0012430540518835187 loss_autoreg: 10.80842399597168 loss_gt: 15.745223045349121\n",
      "it: 1 loss_total: 2.6179609298706055 loss_angle: 0.0014866197016090155 loss_autoreg: 10.627327919006348 loss_gt: 15.537415504455566\n",
      "it: 2 loss_total: 2.2639729976654053 loss_angle: 0.0018578224116936326 loss_autoreg: 8.876625061035156 loss_gt: 13.744524955749512\n",
      "it: 3 loss_total: 2.451185464859009 loss_angle: 0.0027206134982407093 loss_autoreg: 9.808239936828613 loss_gt: 14.676407814025879\n",
      "it: 4 loss_total: 2.548466205596924 loss_angle: 0.0008590085199102759 loss_autoreg: 10.239834785461426 loss_gt: 15.236235618591309\n",
      "it: 5 loss_total: 2.3043899536132812 loss_angle: 0.0014895566273480654 loss_autoreg: 9.052938461303711 loss_gt: 13.976064682006836\n",
      "it: 6 loss_total: 2.3501133918762207 loss_angle: 0.0016591629246249795 loss_autoreg: 9.232776641845703 loss_gt: 14.251764297485352\n",
      "it: 7 loss_total: 2.342954397201538 loss_angle: 0.0008600348373875022 loss_autoreg: 9.225699424743652 loss_gt: 14.195243835449219\n",
      "it: 8 loss_total: 2.210447311401367 loss_angle: 0.0016390951350331306 loss_autoreg: 8.57522201538086 loss_gt: 13.512860298156738\n",
      "it: 9 loss_total: 2.2588868141174316 loss_angle: 0.0012543490156531334 loss_autoreg: 8.790923118591309 loss_gt: 13.785400390625\n",
      "it: 10 loss_total: 2.1436450481414795 loss_angle: 0.0016379381995648146 loss_autoreg: 8.204141616821289 loss_gt: 13.215928077697754\n",
      "it: 11 loss_total: 2.1226284503936768 loss_angle: 0.0016294613014906645 loss_autoreg: 8.176369667053223 loss_gt: 13.033620834350586\n",
      "it: 12 loss_total: 2.039618730545044 loss_angle: 0.002069283276796341 loss_autoreg: 7.733816623687744 loss_gt: 12.641676902770996\n",
      "it: 13 loss_total: 1.8327772617340088 loss_angle: 0.0020078574307262897 loss_autoreg: 6.729794979095459 loss_gt: 11.577898979187012\n",
      "it: 14 loss_total: 2.022864580154419 loss_angle: 0.0024856997188180685 loss_autoreg: 7.6198577880859375 loss_gt: 12.583930015563965\n",
      "it: 15 loss_total: 1.8375405073165894 loss_angle: 0.0023644007742404938 loss_autoreg: 6.737008571624756 loss_gt: 11.614751815795898\n",
      "it: 16 loss_total: 1.9999175071716309 loss_angle: 0.004073006100952625 loss_autoreg: 7.481842517852783 loss_gt: 12.476602554321289\n",
      "it: 17 loss_total: 1.7128709554672241 loss_angle: 0.001865781843662262 loss_autoreg: 6.157227993011475 loss_gt: 10.952823638916016\n",
      "it: 18 loss_total: 1.8849096298217773 loss_angle: 0.000759230344556272 loss_autoreg: 6.942697048187256 loss_gt: 11.898805618286133\n",
      "it: 19 loss_total: 1.8403234481811523 loss_angle: 0.0017642441671341658 loss_autoreg: 6.770988941192627 loss_gt: 11.614603042602539\n",
      "it: 20 loss_total: 1.789204478263855 loss_angle: 0.00246745184995234 loss_autoreg: 6.477936267852783 loss_gt: 11.389434814453125\n",
      "it: 21 loss_total: 1.7940027713775635 loss_angle: 0.0019439896568655968 loss_autoreg: 6.54819393157959 loss_gt: 11.372393608093262\n",
      "it: 22 loss_total: 1.825118064880371 loss_angle: 0.001576489070430398 loss_autoreg: 6.663704872131348 loss_gt: 11.571709632873535\n",
      "it: 23 loss_total: 1.658958911895752 loss_angle: 0.0019145997939631343 loss_autoreg: 5.865429401397705 loss_gt: 10.705013275146484\n",
      "it: 24 loss_total: 1.7345069646835327 loss_angle: 0.0020694590639322996 loss_autoreg: 6.2517523765563965 loss_gt: 11.072622299194336\n",
      "it: 25 loss_total: 1.7838249206542969 loss_angle: 0.0017974572256207466 loss_autoreg: 6.483844757080078 loss_gt: 11.336429595947266\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.005194439087063074 loss_autoreg: 3.0691215991973877\n",
      "it: 1 loss_angle: 0.0052712648175656796 loss_autoreg: 3.1796157360076904\n",
      "it: 2 loss_angle: 0.004837923217564821 loss_autoreg: 3.2794578075408936\n",
      "it: 3 loss_angle: 0.003603936405852437 loss_autoreg: 3.075493335723877\n",
      "it: 4 loss_angle: 0.004269440192729235 loss_autoreg: 3.3253517150878906\n",
      "Finished validation\n",
      "it: 0 loss_total: 1.5875717401504517 loss_angle: 0.0017464621923863888 loss_autoreg: 5.582101345062256 loss_gt: 10.276152610778809\n",
      "it: 1 loss_total: 1.650288701057434 loss_angle: 0.0025847190991044044 loss_autoreg: 5.8433685302734375 loss_gt: 10.633670806884766\n",
      "it: 2 loss_total: 1.5253045558929443 loss_angle: 0.00174372224137187 loss_autoreg: 5.2791523933410645 loss_gt: 9.956457138061523\n",
      "it: 3 loss_total: 1.5550729036331177 loss_angle: 0.001483200816437602 loss_autoreg: 5.378009796142578 loss_gt: 10.157886505126953\n",
      "it: 4 loss_total: 1.6348865032196045 loss_angle: 0.0006438812124542892 loss_autoreg: 5.77399206161499 loss_gt: 10.568434715270996\n",
      "it: 5 loss_total: 1.444981336593628 loss_angle: 0.0017453557811677456 loss_autoreg: 4.877103328704834 loss_gt: 9.555255889892578\n",
      "it: 6 loss_total: 1.4620438814163208 loss_angle: 0.0011932357447221875 loss_autoreg: 4.971351623535156 loss_gt: 9.637154579162598\n",
      "it: 7 loss_total: 1.3515539169311523 loss_angle: 0.0016220130492001772 loss_autoreg: 4.489431381225586 loss_gt: 9.0098876953125\n",
      "it: 8 loss_total: 1.3995558023452759 loss_angle: 0.0018586916849017143 loss_autoreg: 4.69211483001709 loss_gt: 9.284855842590332\n",
      "it: 9 loss_total: 1.4475713968276978 loss_angle: 0.0011051157489418983 loss_autoreg: 4.930426597595215 loss_gt: 9.534235954284668\n",
      "it: 10 loss_total: 1.4376124143600464 loss_angle: 0.0017963987775146961 loss_autoreg: 4.9209113121032715 loss_gt: 9.437248229980469\n",
      "it: 11 loss_total: 1.2972720861434937 loss_angle: 0.0024895910173654556 loss_autoreg: 4.2470221519470215 loss_gt: 8.70080280303955\n",
      "it: 12 loss_total: 1.242316484451294 loss_angle: 0.0014700659085065126 loss_autoreg: 4.030779838562012 loss_gt: 8.377683639526367\n",
      "it: 13 loss_total: 1.192658543586731 loss_angle: 0.0011949192266911268 loss_autoreg: 3.8831424713134766 loss_gt: 8.031493186950684\n",
      "it: 14 loss_total: 1.151138424873352 loss_angle: 0.002206024480983615 loss_autoreg: 3.656771183013916 loss_gt: 7.832552909851074\n",
      "it: 15 loss_total: 1.16947340965271 loss_angle: 0.0017903841799125075 loss_autoreg: 3.7373316287994385 loss_gt: 7.939497947692871\n",
      "it: 16 loss_total: 1.242653250694275 loss_angle: 0.004359704442322254 loss_autoreg: 4.036890029907227 loss_gt: 8.346044540405273\n",
      "it: 17 loss_total: 1.2299540042877197 loss_angle: 0.0035749501548707485 loss_autoreg: 4.007552623748779 loss_gt: 8.256237030029297\n",
      "it: 18 loss_total: 1.080832600593567 loss_angle: 0.0022287338506430387 loss_autoreg: 3.3773436546325684 loss_gt: 7.408694744110107\n",
      "it: 19 loss_total: 1.1439048051834106 loss_angle: 0.002804374787956476 loss_autoreg: 3.6547954082489014 loss_gt: 7.756208419799805\n",
      "it: 20 loss_total: 1.1225665807724 loss_angle: 0.0021532222162932158 loss_autoreg: 3.561476707458496 loss_gt: 7.642656326293945\n",
      "it: 21 loss_total: 1.1234673261642456 loss_angle: 0.0006195671739988029 loss_autoreg: 3.5410258769989014 loss_gt: 7.6874518394470215\n",
      "it: 22 loss_total: 1.140303611755371 loss_angle: 0.0009442349546588957 loss_autoreg: 3.6428654193878174 loss_gt: 7.750727653503418\n",
      "it: 23 loss_total: 1.1121423244476318 loss_angle: 0.0009511202806606889 loss_autoreg: 3.504265546798706 loss_gt: 7.607645034790039\n",
      "it: 24 loss_total: 1.048802137374878 loss_angle: 0.001334126340225339 loss_autoreg: 3.219609260559082 loss_gt: 7.255071640014648\n",
      "it: 25 loss_total: 0.9971621632575989 loss_angle: 0.0015794099308550358 loss_autoreg: 3.016880512237549 loss_gt: 6.938947677612305\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.004054082091897726 loss_autoreg: 1.6744749546051025\n",
      "it: 1 loss_angle: 0.00283501367084682 loss_autoreg: 1.6019854545593262\n",
      "it: 2 loss_angle: 0.0034008303191512823 loss_autoreg: 1.7366615533828735\n",
      "it: 3 loss_angle: 0.004114978946745396 loss_autoreg: 1.731035590171814\n",
      "it: 4 loss_angle: 0.004163749050348997 loss_autoreg: 1.7720645666122437\n",
      "Finished validation\n",
      "it: 0 loss_total: 1.0527979135513306 loss_angle: 0.002220805501565337 loss_autoreg: 3.302309274673462 loss_gt: 7.20346212387085\n",
      "it: 1 loss_total: 1.011434555053711 loss_angle: 0.0017779452027752995 loss_autoreg: 3.14253830909729 loss_gt: 6.9540276527404785\n",
      "it: 2 loss_total: 1.019141435623169 loss_angle: 0.0016611600294709206 loss_autoreg: 3.1927175521850586 loss_gt: 6.98208475112915\n",
      "it: 3 loss_total: 0.8836681842803955 loss_angle: 0.0018101799068972468 loss_autoreg: 2.5292580127716064 loss_gt: 6.2893218994140625\n",
      "it: 4 loss_total: 0.9910577535629272 loss_angle: 0.002032160060480237 loss_autoreg: 3.06579852104187 loss_gt: 6.82445764541626\n",
      "it: 5 loss_total: 0.8707878589630127 loss_angle: 0.0017195430118590593 loss_autoreg: 2.577580451965332 loss_gt: 6.113102912902832\n",
      "it: 6 loss_total: 0.9594630002975464 loss_angle: 0.0010090423747897148 loss_autoreg: 2.889449119567871 loss_gt: 6.695090293884277\n",
      "it: 7 loss_total: 0.9500936269760132 loss_angle: 0.0010589431039988995 loss_autoreg: 2.862262487411499 loss_gt: 6.628084659576416\n",
      "it: 8 loss_total: 0.9129030704498291 loss_angle: 0.0009008816559799016 loss_autoreg: 2.7493391036987305 loss_gt: 6.370683193206787\n",
      "it: 9 loss_total: 0.8721413612365723 loss_angle: 0.0014047372387722135 loss_autoreg: 2.544538736343384 loss_gt: 6.162827491760254\n",
      "it: 10 loss_total: 0.9073577523231506 loss_angle: 0.0014132733922451735 loss_autoreg: 2.7514359951019287 loss_gt: 6.308008193969727\n",
      "it: 11 loss_total: 0.9222199320793152 loss_angle: 0.00127383042126894 loss_autoreg: 2.857578754425049 loss_gt: 6.3518829345703125\n",
      "it: 12 loss_total: 0.7688010931015015 loss_angle: 0.0019634917844086885 loss_autoreg: 2.1988823413848877 loss_gt: 5.469493389129639\n",
      "it: 13 loss_total: 0.8061552047729492 loss_angle: 0.0013588102301582694 loss_autoreg: 2.311034679412842 loss_gt: 5.736929416656494\n",
      "it: 14 loss_total: 0.7160477042198181 loss_angle: 0.0013249097391963005 loss_autoreg: 2.061924934387207 loss_gt: 5.08530330657959\n",
      "it: 15 loss_total: 0.7927341461181641 loss_angle: 0.0017584273591637611 loss_autoreg: 2.361807346343994 loss_gt: 5.547949314117432\n",
      "it: 16 loss_total: 0.7363622188568115 loss_angle: 0.0022300067357718945 loss_autoreg: 2.0639214515686035 loss_gt: 5.277400970458984\n",
      "it: 17 loss_total: 0.720899760723114 loss_angle: 0.0021660071797668934 loss_autoreg: 2.1056156158447266 loss_gt: 5.081721782684326\n",
      "it: 18 loss_total: 0.7391555309295654 loss_angle: 0.00258850515820086 loss_autoreg: 2.1003682613372803 loss_gt: 5.265301704406738\n",
      "it: 19 loss_total: 0.7705904245376587 loss_angle: 0.0019988291896879673 loss_autoreg: 2.273489475250244 loss_gt: 5.412425994873047\n",
      "it: 20 loss_total: 0.7911162376403809 loss_angle: 0.0020611428190022707 loss_autoreg: 2.4298810958862305 loss_gt: 5.460669994354248\n",
      "it: 21 loss_total: 0.6767823696136475 loss_angle: 0.0012533245608210564 loss_autoreg: 1.8760085105895996 loss_gt: 4.879281997680664\n",
      "it: 22 loss_total: 0.7016463279724121 loss_angle: 0.0023930452298372984 loss_autoreg: 1.9877541065216064 loss_gt: 5.004778861999512\n",
      "it: 23 loss_total: 0.7954604029655457 loss_angle: 0.0017198552377521992 loss_autoreg: 2.3935866355895996 loss_gt: 5.543818950653076\n",
      "it: 24 loss_total: 0.7079921364784241 loss_angle: 0.0021044237073510885 loss_autoreg: 2.1184990406036377 loss_gt: 4.940377712249756\n",
      "it: 25 loss_total: 0.7523149847984314 loss_angle: 0.0004696805845014751 loss_autoreg: 2.245429039001465 loss_gt: 5.273024082183838\n",
      "Finished training.\n",
      "it: 0 loss_angle: 0.007708732970058918 loss_autoreg: 1.2338333129882812\n",
      "it: 1 loss_angle: 0.005424514412879944 loss_autoreg: 1.173802137374878\n",
      "it: 2 loss_angle: 0.005190317053347826 loss_autoreg: 0.9990887641906738\n",
      "it: 3 loss_angle: 0.005662990268319845 loss_autoreg: 1.2947598695755005\n",
      "it: 4 loss_angle: 0.007307794876396656 loss_autoreg: 0.9061571359634399\n",
      "Finished validation\n"
     ]
    }
   ],
   "source": [
    "for batch in range(10):\n",
    "    do_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "model_save_path = \"/export/jupyterlab/chengxin/models/git-731f0f\"\n",
    "torch.save(steernet.state_dict(), model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
