{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>angle</th>\n",
       "      <th>torque</th>\n",
       "      <th>speed</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-17 23:10:15.873184606</td>\n",
       "      <td>1479424215873184606</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>left_camera</td>\n",
       "      <td>left/1479424215873184606.png</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>23.003350</td>\n",
       "      <td>37.545269</td>\n",
       "      <td>-122.326485</td>\n",
       "      <td>8.116664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-11-17 23:10:15.877284689</td>\n",
       "      <td>1479424215877284689</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>right_camera</td>\n",
       "      <td>right/1479424215877284689.png</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>23.003919</td>\n",
       "      <td>37.545269</td>\n",
       "      <td>-122.326485</td>\n",
       "      <td>8.123680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-11-17 23:10:15.880976321</td>\n",
       "      <td>1479424215880976321</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>center_camera</td>\n",
       "      <td>center/1479424215880976321.png</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>23.004431</td>\n",
       "      <td>37.545269</td>\n",
       "      <td>-122.326492</td>\n",
       "      <td>8.128418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-11-17 23:10:15.922817911</td>\n",
       "      <td>1479424215922817911</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>left_camera</td>\n",
       "      <td>left/1479424215922817911.png</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>23.007310</td>\n",
       "      <td>37.545261</td>\n",
       "      <td>-122.326500</td>\n",
       "      <td>8.139066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-11-17 23:10:15.927281227</td>\n",
       "      <td>1479424215927281227</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>right_camera</td>\n",
       "      <td>right/1479424215927281227.png</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.380823</td>\n",
       "      <td>23.006074</td>\n",
       "      <td>37.545261</td>\n",
       "      <td>-122.326500</td>\n",
       "      <td>8.144778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101391</td>\n",
       "      <td>2016-11-17 23:49:32.293518518</td>\n",
       "      <td>1479426572293518518</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>center_camera</td>\n",
       "      <td>center/1479426572293518518.png</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024914</td>\n",
       "      <td>11.738325</td>\n",
       "      <td>37.548805</td>\n",
       "      <td>-122.315819</td>\n",
       "      <td>-19.648416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101392</td>\n",
       "      <td>2016-11-17 23:49:32.303971946</td>\n",
       "      <td>1479426572303971946</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>right_camera</td>\n",
       "      <td>right/1479426572303971946.png</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>11.741227</td>\n",
       "      <td>37.548805</td>\n",
       "      <td>-122.315819</td>\n",
       "      <td>-19.648843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101393</td>\n",
       "      <td>2016-11-17 23:49:32.317632186</td>\n",
       "      <td>1479426572317632186</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>left_camera</td>\n",
       "      <td>left/1479426572317632186.png</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>11.743342</td>\n",
       "      <td>37.548805</td>\n",
       "      <td>-122.315811</td>\n",
       "      <td>-19.650489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101394</td>\n",
       "      <td>2016-11-17 23:49:32.343447996</td>\n",
       "      <td>1479426572343447996</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>center_camera</td>\n",
       "      <td>center/1479426572343447996.png</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011082</td>\n",
       "      <td>11.744445</td>\n",
       "      <td>37.548809</td>\n",
       "      <td>-122.315811</td>\n",
       "      <td>-19.654094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101395</td>\n",
       "      <td>2016-11-17 23:49:32.353979282</td>\n",
       "      <td>1479426572353979282</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>right_camera</td>\n",
       "      <td>right/1479426572353979282.png</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.744445</td>\n",
       "      <td>37.548809</td>\n",
       "      <td>-122.315811</td>\n",
       "      <td>-19.655827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101396 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                index            timestamp  width  height  \\\n",
       "0       2016-11-17 23:10:15.873184606  1479424215873184606    640     480   \n",
       "1       2016-11-17 23:10:15.877284689  1479424215877284689    640     480   \n",
       "2       2016-11-17 23:10:15.880976321  1479424215880976321    640     480   \n",
       "3       2016-11-17 23:10:15.922817911  1479424215922817911    640     480   \n",
       "4       2016-11-17 23:10:15.927281227  1479424215927281227    640     480   \n",
       "...                               ...                  ...    ...     ...   \n",
       "101391  2016-11-17 23:49:32.293518518  1479426572293518518    640     480   \n",
       "101392  2016-11-17 23:49:32.303971946  1479426572303971946    640     480   \n",
       "101393  2016-11-17 23:49:32.317632186  1479426572317632186    640     480   \n",
       "101394  2016-11-17 23:49:32.343447996  1479426572343447996    640     480   \n",
       "101395  2016-11-17 23:49:32.353979282  1479426572353979282    640     480   \n",
       "\n",
       "             frame_id                        filename     angle    torque  \\\n",
       "0         left_camera    left/1479424215873184606.png  0.000360  0.375000   \n",
       "1        right_camera   right/1479424215877284689.png  0.000717  0.375000   \n",
       "2       center_camera  center/1479424215880976321.png  0.001039  0.375000   \n",
       "3         left_camera    left/1479424215922817911.png  0.003491  0.394737   \n",
       "4        right_camera   right/1479424215927281227.png  0.003491  0.380823   \n",
       "...               ...                             ...       ...       ...   \n",
       "101391  center_camera  center/1479426572293518518.png  0.000000  0.024914   \n",
       "101392   right_camera   right/1479426572303971946.png  0.000000  0.057556   \n",
       "101393    left_camera    left/1479426572317632186.png  0.000000  0.062500   \n",
       "101394  center_camera  center/1479426572343447996.png  0.000000  0.011082   \n",
       "101395   right_camera   right/1479426572353979282.png  0.000000  0.000000   \n",
       "\n",
       "            speed        lat        long        alt  \n",
       "0       23.003350  37.545269 -122.326485   8.116664  \n",
       "1       23.003919  37.545269 -122.326485   8.123680  \n",
       "2       23.004431  37.545269 -122.326492   8.128418  \n",
       "3       23.007310  37.545261 -122.326500   8.139066  \n",
       "4       23.006074  37.545261 -122.326500   8.144778  \n",
       "...           ...        ...         ...        ...  \n",
       "101391  11.738325  37.548805 -122.315819 -19.648416  \n",
       "101392  11.741227  37.548805 -122.315819 -19.648843  \n",
       "101393  11.743342  37.548805 -122.315811 -19.650489  \n",
       "101394  11.744445  37.548809 -122.315811 -19.654094  \n",
       "101395  11.744445  37.548809 -122.315811 -19.655827  \n",
       "\n",
       "[101396 rows x 12 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_csv = pd.read_csv('/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export_png/interpolated.csv')\n",
    "\n",
    "camera_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# defining our own Dataset class\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class UdacityDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, select_camera=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            select_camera (string): 'left_ / right_ / center_camera'\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        camera_csv = pd.read_csv(csv_file)\n",
    "        if select_camera:\n",
    "            camera_csv = camera_csv[camera_csv['frame_id']==select_camera]\n",
    "        self.camera_csv = camera_csv\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.camera_csv)\n",
    "    \n",
    "    def read_data(self, idx):\n",
    "        path = os.path.join(self.root_dir, self.camera_csv['filename'].iloc[idx])\n",
    "        image = io.imread(path)\n",
    "        timestamp = self.camera_csv['timestamp'].iloc[idx]\n",
    "        frame_id = self.camera_csv['frame_id'].iloc[idx]\n",
    "        angle = self.camera_csv['angle'].iloc[idx]\n",
    "            \n",
    "        return image, timestamp, frame_id, angle\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        if idx is int:\n",
    "            image, timestamp, frame_id, angle = read_data(idx)\n",
    "        else:\n",
    "            image = []\n",
    "            timestamp = []\n",
    "            frame_id = []\n",
    "            angle = []\n",
    "            \n",
    "            for i in idx:\n",
    "                im, ti, fr, an = self.read_data(i)\n",
    "                image.append(im)\n",
    "                timestamp.append(ti)\n",
    "                frame_id.append(fr)\n",
    "                angle.append(an)\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(np.array(image))\n",
    "            \n",
    "        sample = {'image': image,\n",
    "                  'timestamp': timestamp,\n",
    "                  'frame_id': frame_id,\n",
    "                  'angle': angle}\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pic should be 2/3 dimensional. Got 4 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-65236ed74f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mudacity_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBatchSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# dataloader = DataLoader(udacity_dataset, batch_size=4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-253-2cbed49d9bbd>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         sample = {'image': image,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pic should be 2/3 dimensional. Got {} dimensions.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pic should be 2/3 dimensional. Got 4 dimensions."
     ]
    }
   ],
   "source": [
    "# test the UdacityDataset class\n",
    "\n",
    "def show_sample(sample):\n",
    "    plt.imshow(sample['image'])\n",
    "    plt.title(\"cam: {} angle: {}\".format(sample['frame_id'], sample['angle']))\n",
    "\n",
    "# to load as normal images:    \n",
    "\n",
    "# udacity_dataset = UdacityDataset(csv_file='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/interpolated.csv',\n",
    "#                                  root_dir='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/',\n",
    "#                                  transform=None,\n",
    "#                                  select_camera='center_camera')\n",
    "# print(udacity_dataset.camera_csv['filename'].iloc[0])\n",
    "\n",
    "# fig = plt.figure()\n",
    "\n",
    "# for i in range(3):\n",
    "#     sample = udacity_dataset[i]\n",
    "#     ax = plt.subplot(1, 4, i%4+1)\n",
    "#     plt.tight_layout()\n",
    "#     ax.axis('off')\n",
    "#     show_sample(sample)\n",
    "#     plt.pause(0.001)\n",
    "    \n",
    "#     if i % 4 == 0:\n",
    "#         plt.show()\n",
    "\n",
    "# to load as tensors\n",
    "\n",
    "udacity_dataset = UdacityDataset(csv_file='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/interpolated.csv',\n",
    "                                 root_dir='/export/jupyterlab/data/udacity-challenge-2/Ch2_002_export/',\n",
    "                                 transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# print(\"type of image data:\")\n",
    "# print(type(udacity_dataset[0]['image']))\n",
    "# print(udacity_dataset[1]['image'].shape)\n",
    "\n",
    "# using DataLoader and batch_size\n",
    "# this allows multithreading so it has a higher efficiency\n",
    "\n",
    "sampler = SequentialSampler(udacity_dataset)\n",
    "dataloader = DataLoader(udacity_dataset, sampler=BatchSampler(sampler, batch_size=1, drop_last=False))\n",
    "# dataloader = DataLoader(udacity_dataset, batch_size=4)\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(type(sample_batched['image']))\n",
    "    print(sample_batched['image'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Batch with consecutive frames taken from input data\n",
    "\n",
    "from torch.utils.data import Sampler\n",
    "import random\n",
    "\n",
    "class ConsecutiveBatchSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, data_source, batch_size, padding, last_batch=None, shuffle=True):\n",
    "        r\"\"\" Sampler to generate consecutive Batches\n",
    "        \n",
    "        Args:\n",
    "            data_source: Source of data\n",
    "            batch_size: Number of frames in each batch\n",
    "            padding: Number of frames to insert before each batch\n",
    "            last_batch: Operation to the last batch. Use 'drop', 'fill' or None\n",
    "            shuffle: Wether to shuffle the data\n",
    "        \"\"\"\n",
    "        self.data_source = data_source\n",
    "        \n",
    "        assert batch_size >= 1, \"Invalid batch size: {}\".format(batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        assert padding >= 0, \"Invalid padding size: {}\".format(padding)\n",
    "        self.padding = padding\n",
    "        \n",
    "        assert last_batch in ['drop', 'fill', None], \"Invalid option last_batch={}\".format(last_batch)\n",
    "        self.last_batch=last_batch\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def __iter__(self):\n",
    "        length = len(self.data_source)\n",
    "        start_indices = list(range(0, length, self.batch_size))\n",
    "        if self.shuffle:\n",
    "            random.shuffle(start_indices)\n",
    "        \n",
    "        for ind in start_indices:\n",
    "            batch = []\n",
    "            \n",
    "            if ind - self.padding < 0:\n",
    "                batch.extend([0]*(self.padding - ind) + list(range(0, ind)))\n",
    "            else:\n",
    "                batch.extend(list(range(ind - self.padding, ind)))\n",
    "            \n",
    "            if ind + self.batch_size > length:\n",
    "                if self.last_batch == 'drop':\n",
    "                    continue\n",
    "                elif self.last_batch == 'fill':\n",
    "                    batch.extend(list(range(ind, length)) + list(range(0, self.batch_size-(length-ind))))\n",
    "                else:\n",
    "                    batch.extend(list(range(ind, length)))\n",
    "            else:\n",
    "                batch.extend(list(range(ind, ind+self.batch_size)))\n",
    "            \n",
    "            yield batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        length = len(self.data_source)\n",
    "        \n",
    "        if length % batch_size == 0 or self.last_batch == 'fill':\n",
    "            return length // batch_size\n",
    "        \n",
    "        if self.last_batch == 'drop':\n",
    "            return length // batch_size\n",
    "        \n",
    "        return length // batch_size + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 13, 14, 15], [4, 5, 6, 7], [0, 1, 2, 3], [16, 17, 18, 19], [8, 9, 10, 11]]\n",
      "[[4, 16, 9, 3], [2, 7, 8, 13], [5, 10, 11, 14], [15, 6, 18, 19], [1, 0, 17, 12]]\n"
     ]
    }
   ],
   "source": [
    "# # test the ConsecutiveBatchSampler\n",
    "\n",
    "from torch.utils.data import BatchSampler, SequentialSampler, RandomSampler\n",
    "\n",
    "dummy_dataset = list(range(0, 20))\n",
    "cbs = ConsecutiveBatchSampler(data_source=dummy_dataset, batch_size=4, shuffle=True, last_batch=None, padding = 0)\n",
    "print(list([a for a in cbs]))\n",
    "bs = BatchSampler(RandomSampler(dummy_dataset), batch_size=4, drop_last=False)\n",
    "print(list([a for a in bs]))\n",
    "    \n",
    "#test the sampler on DataLoader\n",
    "\n",
    "# batch_sampler = ConsecutiveBatchSampler(data_source=udacity_dataset, batch_size=4, shuffle=True, last_batch=None, padding=1)\n",
    "# dataloader = DataLoader(udacity_dataset, sampler=batch_sampler, num_workers=1)\n",
    "# for i_batch, sample_batched in enumerate(dataloader):\n",
    "#     print(sample_batched['image'].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "import torch.nn as nn\n",
    "\n",
    "class Conv3DModel(nn.Module, W_in=640, H_in=480):\n",
    "    def __init__(self):\n",
    "        super(Conv3DModel, self).__init__()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
